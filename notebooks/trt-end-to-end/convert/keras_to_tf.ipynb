{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for converting a Keras Model to a TensorFlow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "../../../tmp/trt_end_to_end/train/basic/001/basic_epoch001_2019-09-03T19:15.h5\n",
      "../../../tmp/trt_end_to_end/train/basic/001/basic_epoch001_2019-09-03T19:15.md\n",
      "../../../tmp/trt_end_to_end/train/basic/001/params.json\n",
      "../../../tmp/trt_end_to_end/train/batchn/001/batchn_epoch001_2019-09-03T19:28.h5\n",
      "../../../tmp/trt_end_to_end/train/batchn/001/batchn_epoch001_2019-09-03T19:28.md\n",
      "../../../tmp/trt_end_to_end/train/batchn/001/params.json\n",
      "../../../tmp/trt_end_to_end/train/conv/001/conv_epoch001_2019-09-03T19:30.h5\n",
      "../../../tmp/trt_end_to_end/train/conv/001/conv_epoch001_2019-09-03T19:30.md\n",
      "../../../tmp/trt_end_to_end/train/conv/001/params.json\n",
      "../../../tmp/trt_end_to_end/train/resnet50/001/params.json\n",
      "../../../tmp/trt_end_to_end/train/resnet50/001/resnet50_epoch001_2019-09-03T19:31.h5\n",
      "../../../tmp/trt_end_to_end/train/resnet50/001/resnet50_epoch001_2019-09-03T19:31.md\n",
      "\n",
      "Convert (Saved Graph):\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/checkpoint\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/tf_model_basic_epoch001_2019-09-03T19:15.data-00000-of-00001\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/tf_model_basic_epoch001_2019-09-03T19:15.index\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/tf_model_basic_epoch001_2019-09-03T19:15.meta\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/checkpoint\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/tf_model_batchn_epoch001_2019-09-03T19:28.data-00000-of-00001\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/tf_model_batchn_epoch001_2019-09-03T19:28.index\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/tf_model_batchn_epoch001_2019-09-03T19:28.meta\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/checkpoint\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/tf_model_conv_epoch001_2019-09-03T19:30.data-00000-of-00001\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/tf_model_conv_epoch001_2019-09-03T19:30.index\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/tf_model_conv_epoch001_2019-09-03T19:30.meta\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "echo 'Train:'\n",
    "TRAIN_DIR=../../../tmp/trt_end_to_end/train\n",
    "find ${TRAIN_DIR} -type f | sort\n",
    "echo\n",
    "echo 'Convert (Saved Graph):'\n",
    "CONVERT_TF_SAVED_GRAPH_DIR=../../../tmp/trt_end_to_end/convert/tf/saved\n",
    "find ${CONVERT_TF_SAVED_GRAPH_DIR} -type f | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_NAME = 'resnet50'\n",
    "_EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.trt_end_to_end_constants import *\n",
    "_NAME, _EPOCH, _TIME = get_params(_NAME, _EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_filename = H5_FILE_FORMAT % (_NAME, _EPOCH, _TIME)\n",
    "_train_save_to_dir = get_train_dir(_NAME, _EPOCH)\n",
    "_train_filepath = os.path.join(_train_save_to_dir, _train_filename)\n",
    "assert os.path.exists(_train_filepath), \"Not exists: %s\" % _train_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set learning phase 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import the needed libraries\n",
    "import tensorflow as tf\n",
    "print(tf.__name__, tf.__version__, sep='-')\n",
    "tf.keras.backend.set_learning_phase(0) # use this if we have batch norm layer in our network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0903 19:33:35.543020 140236397193024 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0903 19:33:35.543934 140236397193024 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0903 19:33:35.546770 140236397193024 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../tmp/trt_end_to_end/train/resnet50/001/resnet50_epoch001_2019-09-03T19:31.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 19:33:37.574040 140236397193024 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model_filename = H5_FILE_FORMAT % (_NAME, _EPOCH, _TIME)\n",
    "model_filepath = os.path.join(_train_save_to_dir, model_filename)\n",
    "print(model_filepath)\n",
    "\n",
    "keras_model = tf.keras.models.load_model(model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/tf_model_conv_epoch001_2019-09-03T19:30.data-00000-of-00001\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/tf_model_conv_epoch001_2019-09-03T19:30.meta\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/checkpoint\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/tf_model_conv_epoch001_2019-09-03T19:30.index\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/tf_model_basic_epoch001_2019-09-03T19:15.index\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/checkpoint\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/tf_model_basic_epoch001_2019-09-03T19:15.data-00000-of-00001\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/tf_model_basic_epoch001_2019-09-03T19:15.meta\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/tf_model_batchn_epoch001_2019-09-03T19:28.data-00000-of-00001\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/tf_model_batchn_epoch001_2019-09-03T19:28.meta\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/checkpoint\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/tf_model_batchn_epoch001_2019-09-03T19:28.index\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "CONVERT_TF_SAVED_GRAPH_DIR=../../../tmp/trt_end_to_end/convert/tf/saved\n",
    "mkdir -p ${CONVERT_TF_SAVED_GRAPH_DIR}\n",
    "#rm -f ./${CONVERT_TF_DIR}/*\n",
    "find ${CONVERT_TF_SAVED_GRAPH_DIR} -type f | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model is successfully converted to TF model in ../../../tmp/trt_end_to_end/convert/tf/saved/resnet50/001\n"
     ]
    }
   ],
   "source": [
    "file_prefix = SAVED_GRAPH_FILE_FORMAT % (_NAME, _EPOCH ,_TIME)\n",
    "save_to_dir = get_saved_graph_dir(_NAME, _EPOCH)\n",
    "save_to = os.path.join(save_to_dir, file_prefix)\n",
    "\n",
    "# save the model to Tensorflow model\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.keras.backend.get_session()\n",
    "save_path = saver.save(sess, save_to)\n",
    "\n",
    "print(\"Keras model is successfully converted to TF model in\", save_to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/checkpoint\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/tf_model_basic_epoch001_2019-09-03T19:15.data-00000-of-00001\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/tf_model_basic_epoch001_2019-09-03T19:15.index\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/basic/001/tf_model_basic_epoch001_2019-09-03T19:15.meta\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/checkpoint\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/tf_model_batchn_epoch001_2019-09-03T19:28.data-00000-of-00001\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/tf_model_batchn_epoch001_2019-09-03T19:28.index\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/batchn/001/tf_model_batchn_epoch001_2019-09-03T19:28.meta\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/checkpoint\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/tf_model_conv_epoch001_2019-09-03T19:30.data-00000-of-00001\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/tf_model_conv_epoch001_2019-09-03T19:30.index\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/conv/001/tf_model_conv_epoch001_2019-09-03T19:30.meta\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/resnet50/001/checkpoint\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/resnet50/001/tf_model_resnet50_epoch001_2019-09-03T19:31.data-00000-of-00001\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/resnet50/001/tf_model_resnet50_epoch001_2019-09-03T19:31.index\n",
      "../../../tmp/trt_end_to_end/convert/tf/saved/resnet50/001/tf_model_resnet50_epoch001_2019-09-03T19:31.meta\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "CONVERT_TF_SAVED_GRAPH_DIR=../../../tmp/trt_end_to_end/convert/tf/saved\n",
    "find ${CONVERT_TF_SAVED_GRAPH_DIR} -type f | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
